# Gemini Chat PWA - 历史经验与踩坑记录

## 核心目标

本次更新的主要目标是扩展 **Gemini Chat PWA** 的能力，通过整合 **Supabase** 和 **PostgreSQL** 构建带后端数据库和具备弹性用户认证的系统。具体来说，实现了以下功能：
1. **多端云同步：** 实现基于 自定义 4 位激活码 (PIN) 的验证系统，用户可以在多台设备间安全地同步和读取自己的自定义 `system_instructions`（系统设定）。
2. **持续记忆 (RAG)：** 利用 RAG（检索增强生成），允许 AI 从任何聊天中提取核心事实和用户偏好，并将其向量化存入数据库。当开启新对话时，系统会自动提取这些上下文，使 AI 拥有连续的长期个人记忆。

## 架构实现细节

### Supabase 数据库表结构设计
在 Supabase 中构建了如下表结构：
- `users`: 管理后台生成的用户映射表。
- `activation_codes`: 定制的 4 字符激活码，作为绕过复杂邮箱登录的 “入场券”，由管理员分发。
- `user_devices`: 将用户的设备指纹 (`device_fingerprint`) 和用户 ID 绑定，用于设备访问控制。
- `system_instructions`: 简单的云端同步文本库，在用户登录时自动同步。
- `user_vectors`: 利用 `pgvector` 扩展实现的个人向量数据库，由 `user_id` 进行 1对1 隔离。

### Admin 管理后台
通过 `.env` 中的固定密码保护进入的控制台 (`/admin`)：
- 分配了一个可视化界面，可以直接生成四位数的独立邀请码，便于私有化分发。
- 支持在 `user_devices` 层面一键吊销对应设备的访问权限。

### RAG 记忆流转机制 (检索增强)
记忆能力依靠标准的语义相似度检索：
1. **知识提取 (`/api/vectorize`)：** 前端从本地离线会话中提取当下的对话文本，交给 `gemini-3-flash-preview` 提炼出一段“核心事实总结”。
2. **向量化编码：** 将提炼出的纯文本交给专精向量化的 `gemini-embedding-001` 模型，生成一组包含 `3072` 个浮点数维度的精确特征向量。
3. **入库存储：** 这段向量附带对应用户的 `uuid` 被安全地写入 Supabase 个人隔离区。
4. **触发回忆 (`/api/chat`)：** 这是一个自动拦截机制：聊天发出前，系统会先把最新的提问编码，并调用数据库写好的 `match_user_vectors` RPC (Remote Procedure Call) 函数进行余弦距离 (Cosine Distance) 计算。若匹配的分数大于设定的阈值 (`0.4`)，则将被唤醒的记忆直接打包悄悄塞到大模型的系统提示词 (System Prompt) 底部。

## 遇到的核心挑战与历史踩坑点

**1. PgVector 索引维度溢出 `(Error 54000)`**
在初次建表时，尝试给 `user_vectors` 的特征向量列加上高阶的 HNSW (分层导航小世界) 算法索引，导致运行报错崩溃。原因是 Postgres 的 `pgvector` 扩展在构建快速 HNSW 索引时，**最高只支持 2000 个维度**。而 Google 最新一代的高质量向量模型 `gemini-embedding-001` 吐出的数据高达 **3072 维**！
*【解决方案】：* 考虑到本项目的向量数据是强关联私有 `uuid` 的。对于个人知识库而言，总数据量极为有限。因此最终**果断舍弃了 HNSW 索引**。对于 3072 维的高阶数据，不建索引直接采用精确最邻近扫描法 (Exact Nearest Neighbor Search / KNN 暴力扫表) ，不仅完全规避了维度受限问题，在小数据量集下扫描速度也依然高达毫秒级，且检索精准度达到了 100%。

**2. Vercel AI SDK 文本解析地雷 (空数据幽灵)**
在测试记忆提取时，模型将提炼好的“成功”结果源源不断地写进数据库，但记忆永远抓不出来。查看底层查证后发现，存进库里的永远是："The User and Assistant entries are marked as 'undefined'"。
问题出在于，Vercel 推出的 `useChat()` AI React 组件 Hook 的底层数据结构发生了暗改。旧版的 `m.text` 或 `m.content` 在面对含有附件或复杂格式的聊天时，实际的对话文本并非明文包裹在这两个字段下，而是被塞进了一个极为隐蔽的嵌套数组 `m.parts[type='text']` 内。这导致之前的接口代码拦截到了全是 `undefined` 的空气，大模型只能提炼“无效信息”。
*【解决方案】：* 对 `/api/vectorize` 与 `/api/chat` 的文本脱壳逻辑进行了彻底的健壮性重构。写了一套智能嗅探算法优先寻找 `m.parts`，如果没有再去兜底降级匹配 `m.content` 与明文 `m.text`，彻底清除了截取文本为空的历史遗留痛点。

## 验证与结果
- **授权链路完整：** Admin 管理员创建新 Ticket -> 访客设备输入 PIN 激活 -> 获取云端 System Prompt 成功。
- **动态记忆生效：** 将极具个性的个人细节注入到无状态聊天界面提取后，即便开启新标签页、切换对话窗口，通过自然语言触发询问，AI 能直接调取这些过往设定的特征精确应答。RAG 双向检索全链路已完美打通并趋于稳定。
